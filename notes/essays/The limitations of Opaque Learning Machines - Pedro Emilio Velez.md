The Limitations of Opaque Learning Machines

Cuando la IA funciona, funciona bien. Pero cuando no, no sabemos ni por qué ni qué cambiar.
No sabes si el problema está en el programa, en el método, o porque el entorno cambió. 
Algunos dicen que no necesitamos transparencia, así como no conocemos el cerebro, pero funciona. Así, podemos descartar la transparencia en estos casos. 
Sistemas no transparentes pueden hacer trabajos increíbles, y nuestro cerebro es ejemplo de ellos.
Juda Pearl trata de entender las limitaciones teóricas y examinar cómo estas limitaciones se pueden superar, todo en el contexto de tareas basadas en razonamiento causal.
El entendimiento da a la inteligencia, y esto es claro. La IA funciona, pero hasta que no la logremos entender, no podremos poner las bases de un modelo fuerte que modele y emule el razonamiento humano. 
Cambiar los parámetros de un modelo ayudan a que evolucione como la teoría de Darwin, pero ¿cómo podemos explicar el proceso evolutivo que hizo que creáramos telescopios?
Podemos ver las limitaciones del razonamiento causal en varios niveles:
1.	¿cómo al ver un evento cambia el pensamiento de otro? 
2.	¿Qué puede decirte el síntoma de la enfermedad? 
3.	Qué pasa si si hacemos algo?
4.	Qué pasa si fuera diferente?
Concluye Juda Pearl que existen limitaciones de una AI, deberemos de entender y colaborar perfectmanete los datos y los modelos para poder hacer algo fuerte. Concluye con una frase muy interesante:
Opaque learning systems may get us to Babylon, but not to Athens
Me pone a reflexionar lo siguiente, qué barreras tendremos con los modelos actuales? Podremos emular el comportamiento humano en el futuro? Cómo podemos esquematizar los conceptos de las redes neuronales y usar el razonamiento causal para conceptualizarlas?
Este escrito es sumamente interesante, y Juda Pearl tiene mucho por contar.
