
# The Limitations of Opaque Learning Machines
**José Alberto Torres León**

En este artículo, Judea Pearl expone sus inquietudes con respteco del machine learning, el deep learning y los problemas de las máquinas que "funcionan pero no sabemos porqué".

En general, el artículo menciona que deberíamos cuestionarnos el uso de tecnologías como el Deep Learning que dan resultados "correctos" a partir del análisis de una gran catidad de datos, el ajuste de una cantidad igual o mayor de parámteros del modelo y la minimización de una ecuación de error.

Coincido en que las redes neuronales profundas no son algoritmos transparentes, pero tampoco estoy de acuerdo con quienes dicen que no saben porqué funcionan pero funcionan. Aunque no podemos decir con certeza qué significa cada peso sináptico y bias de una red, sí es posible darle un sentido a los resultados que se obtienen de ella, ya que todo lo que puede dar como resultado una red profunda es algo que aprendío de los datos de entrenamiento, entonces el "no se porqué funciona" se traduce en un "no sé qué le dí como entrada a la red, no sé que estoy evaluando, no sé como entrenar un red neuronal".

Con esto, quiero dejar claro que en realidad las técnicas de machine learning y en particular, de Deep Learning, no son tan opacas como se dice que son, aunque es cierto que hay pocos mecanismos formales para quitar esa opacidad de su funcionamiento.

Por otro lado, Pearl menciona que las técnicas actuales de ML tiene sus limitantes, lo cuál también es cierto. Erroneamente se ha especulado tanto sobre estas herramientas que las venden y promocionan como si fuesen soluciones a casi todos los problemas de la industria y el mundo real, sin embargo, esas grandes expectativas generan decepción cuando estos algoritmos son implementados en soluciones reales y no cumplen con todas aquellas promesas del vendedor.

Dados los mecanismo con los que funcionan la mayoría de los métodos de ML y DL en el mercado, que los sitúan como casos de aprendizaje supervisado y no supervisado, principalmente, no hay manera de cumplir con todas las promesas que se dicen y mucho menos de dar respuesta a preguntas que revasen los datos de entrenamiento y requieran de intervenir en el universo del conocimiento del algoritmo o hacer análisis retrospectivo sobre dicho universo.

Me parece que con este artículo, Pearl busca convencernos de que no es conveniente enfocar la investigación de IA en un único tipo de algoritmos, por prometedores que estos parezcan, sino que es necesario seguir cuestionando las herramientas de las que disponemos y proponer nuevas, ejercitar el razonamiento retrospectivo y creativo en busca de mejores mecanismos de apendizaje automático.



```python

```
