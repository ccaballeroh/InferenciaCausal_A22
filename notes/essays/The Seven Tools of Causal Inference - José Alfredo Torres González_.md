Centro de Investigación en Computación del IPN
José Alfredo Torres Gonzalez
B210618
23/02/2022

**Reporte sobre The Seven Tools of Causal Inference**

El auge de los sistemas de inteligencia artificial basados en el aprendizaje máquina, ha traído consigo un sin fin de aplicaciones que a su vez han elevado las expectativas del público y ha generado una sensación de estar ya muy cerca de presenciar sistemas de IA con una capacidad cognitiva de nivel humano. Sin embargo, hay ciertos obstáculos y limitantes en estos sistemas, que imposibilitarán su crecimiento, como la incapacidad de reaccionar favorablemente a estímulos para lo cuales no han sido entrenados o su poca transparencia en los procesos, que lo limita de poder explicar las razones detrás de cada predicción, o el poco entendimiento que tienen de las conexiones causa-efecto. De acuerdo con Judea Pearl, es indispensable prestar atención a dichos impedimentos teóricos fundamentales, ya que de lo contrario nos será cada vez más y más lejano el día cuando por fin se llegue a desarrollar una IA de nivel humano.

De acuerdo con Pearl, un apropiado entendimiento de las conexiones causa-efecto, permitirán a las computadoras generar una representación de su entorno, cuestionarse dicha abstracción, manipularla y poder responder a preguntas elementales y características de la cognición humana como “¿Qué si…?”, que son preguntas imposibles de responder por sistemas cuyo funcionamiento es solamente estadístico, como lo serían los sistemas de Machine Learning. Pearl asegura que todos esos obstáculos podrían ser superados si se usan las herramientas de modelado causal, como lo serían los diagramas causales.

Una de las aportaciones de Pearl fue la forma de clasificar información causal en términos del tipo de preguntas que cada clase puede responder y se dividen en asociación, intervención y contrafáctico. El primer nivel se basa únicamente en relaciones estadísticas, que facilitan predicción con base la observación de datos; el segundo nivel involucra no sólo ver lo que es, si no cambiar lo que se ve y responder a preguntas como sería “¿Que pasaría si hago x?”, y finalmente el tercer nivel es modo razonar mucho más filosófico que respondería a preguntas como “¿Por qué?, ¿X causó a Y?, ¿Qué si hubiera actuado diferente?”, que ya serían mucho más introspectivas y es el más alto, ya que si se cuenta con un modelo capaz de responder este tipo de preguntas, también sería capaz de dar respuestas a las dos categorías anteriores. La capa de asociación se caracteriza por probabilidad condicional como P(x|y) = p y se puede computar de forma eficiente; en el caso de un nivel de Intervención, se trabaja con oraciones del orden P(y|do(x),z), que pueden ser aprendidas por un humano mediante la interacción con su entorno y en una IA esto no puede ser inferido por meras observaciones pasivas; por otro lado lo contrafáctico se expresa de la forma P(yx | x’, y’), que sentencias sólo posibles de responder cuando el modelo se basa en relaciones funcionales o estructurales.

La matemáticas han cambiado demasiado en los últimos años y se han desarrollado lenguajes para manejar causas y efectos; herramientas que transforman el análisis causal en elementos matemáticos y de esta forma poder expresar preguntas causales de manera formal y manejar los datos para estimar respuestas. Este tipo de herramientas ha sido de mucha ayuda en otras áreas como las ciencias sociales y la epidemiología, donde los diagramas causales se han convertido en su día a día, ayudándoles a extraer relaciones causales.

A esta clase de herramientas llamadas por Pearl como modelos causales estructurales, consisten de tres partes que serían modelos gráficos, ecuaciones estructurales y lógica contrafáctica y de intervención. Los modelos gráficos sirven para representar to que se sabe del entorno, las contrafácticas sirven para poder articular correctamente lo que se desea saber, pero las ecuaciones estructurales unen ambas en una semántica sólida. Se describe el motor de inferencia, para referirse a los modelos causales estructurales y acepta tres tipos de entrada que serían suposiciones, entradas y datos y genera tres salidas que serían Índices de estimación, estimación y ajuste.

Pearl describe siete tareas logradas por los modelos causales estructurales y serían: Codificación de suposiciones causales: Transparencia y comprobabilidad; do-calculus y el control de la confusión; la algoritmización de los contrafactuales; análisis de mediación y evaluación de efectos directos e indirectos; adaptabilidad, validez externa y sesgo de selección de la muestra; recuperación de datos faltantes; descubrimiento causal. En el primero “transparencia” le permite al analista discernir si los supuestos son plausibles y la comprobabilidad permite saber si dichos supuestos son compatibles con los datos; en el segundo se refiere a la tarea de seleccionar las covariables que ayuden a controlar la confusión mediante un algoritmo simple; el tercero tiene una representación gráfica y sirve para determinar si la probabilidad de una oración contrafáctica es estimable con base a estudios experimentales u observacionales; la cuarta se refiere a los mecanismos que transmiten los cambios de una causa a sus efectos; la quinta se refiere a una metodología para superar el sesgo debido a cambios ambientales y controlar disparidades entre muestras no representativas y una población objetivo; la sexta se refiere a modelos causales para datos faltantes siempre que se cumplan las condiciones para generar una estimación consistente de la relación deseada; finalmente la siete se refiere a la posibilidad de inferir, mediante suposiciones moderadas, el conjunto de modelos que son compatibles con los datos, para representar dicho conjunto de forma compacta, también se describe un método para descubrir la direccionalidad causal basándose en la descomposición funcional y otro de descubrimiento causal basado en la detección de “shocks” o cambios locales en el entorno.

En resumen, de acuerdo con Judea Pearl, se deberá seguir un camino dividido en 3 partes donde la primera parte es la escalera de la causalidad, que es la base de la inferencia causal, la segunda parte es el motor de inferencia que combina datos con un modelo causal para producir respuestas a consultas de interés y la tercera son “Las 7 herramientas”, que son tareas cognitivas que podemos hacer ahora con la ayuda de la inferencia causal y que no podíamos hacer antes. Se espera que la comunidad de inteligencia artificial lo tome en cuenta para aprender lo que se necesita para traducirlo en tareas más generales de inteligencia. Pearl asegura pertenecer a la escuela tradicional de inteligencia artificial y espera se tomen en cuenta sus consejos, ya que no logra ver un futuro para la inteligencia artificial sin la inferencia causal.

