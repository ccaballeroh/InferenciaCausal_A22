# El aprendizaje opaco y sus limitaciones
## por: Cristian Camilo Segura Morales

           

Es cierto que la inteligencia artificial se ha involucrado cada día más en la realización de muchas actividades que realizamos las personas en nuestro día a día y de una manera muy personal llegando a desempeñar tareas que resultaban ser complicadas o que llevaban un buen tiempo en su implementación a un modelo en el cual se pueden llevar a cabo en muy cortos intervalos de tiempo y con unos resultados bastante buenos que llegan a generar bastante sorpresa e incluso algunas veces desconcierto. Es precisamente el machine learning el cual ha permitido este desarrollo y la implementación de aquellos sistemas que denominamos inteligentes lo cual ha abierto las puertas a un nuevo debate: ¿con base a qué ruta de decisiones una Inteligencia Artificial llega a la obtención de un resultado? Es de conocimiento general que estos modelos son entrenados con bastantes datos que mediante modelos estadísticos realizan el ajuste de parámetros para así finalmente llegar a una configuración con un alto nivel de desempeño el cual funciona muy bien e inclusive a veces esta afirmación se convierte en una pregunta: ¿y cómo es que funciona tan bien?

Esta incertidumbre es la que da la demonización de opacos en donde muchas veces se desconoce el camino que toma el sistema para tomar una decisión, pero aun así se genera un resultado o una acción con base a un conjunto de entradas generando así una reacción. Pero es precisamente este esquema opaco en cierta forma se convierte en un impedimento para la inclusión de ciertos factores que existen en la forma como razonamos los humanos y consiste en una serie de afirmaciones que incluso llega a afectarnos en las acciones que realizamos en nuestro día a día y son las famosas “y si hubiera hecho esto” o “qué pasaría si hago esto”. Veamos, por ejemplo, los sistemas de conducción autónoma en donde un sistema es entrenado para moverse por cierto espacio en condiciones óptimas de desplazamiento trasladándose desde un punto inicial hasta un punto final y si las condiciones de las diferentes vías son las ideales el sistema cumplirá la tarea para la que fue implementado de una manera bastante acertada. Pero, un sistema de conducción autónomo no cuenta con la capacidad de poder previsualizar situaciones en las que puede verse afectado su desempeño con preguntas como, ¿Qué acción tomar en caso de que se presente un accidente de tránsito en el desplazamiento? ¿si se llegan a atravesar dos personas en la vía y una es un niño y la otra es un anciano que acción debería tomar? ¿hay prioridad de una vida sobre la otra? ¿Qué pasa si se incluye un nuevo elemento de la vía para el cual no estaba preparado encontrar? ¿es mejor pasar por alrededor, frenar, pasar sobre él? Es muy probable que el vehículo simplemente responda ante una de estas situaciones de acuerdo con la forma en que se realizó su entrenamiento que podría ser simplemente una directiva de tomar las decisiones priorizando la vida del conductor quien por decirlo de alguna forma es quien está pagando por el actuando conforme a esta directriz y no como resultado de una decisión con base a un escenario que se había podido llegar a predecir con anticipación de acuerdo con diferentes señales el entorno como que la causa del siniestro pudo haberse generado por la baja visibilidad en la vía debido a la niebla y adicionalmente había lluvia en ese momento lo que cambiaba las condiciones del suelo y lo volvía mucho más liso. Ésta es la principal diferencia entre una característica de los seres humanos que aún es bastante complicada de implementar en un sistema inteligente y es la capacidad de anteponerse a una situación que pueda afectar el desempeño del mismo generando consecuencias a los actores que intervienen o presentan algún tipo de interacción con el sistema.

El marketing es una de las actividades en la mayoría de las empresas de desarrollo de sistemas inteligentes cuyo objetivo es generar un elevado índice de expectativa hacia el público al que va dirigido donde estos sistemas son vendidos como la solución a muchos de las actividades del día a día donde se da la imagen de que son perfectos y no tienen ningún tipo de fallo lo que genera una falsa sensación de seguridad a los diferentes usuarios donde pasan de convertirse de un elemento de apoyo a generar una dependencia total de este por ello es que cuando una de estas inteligencias falla el escándalo mediático es tan grande ya que si fuera un humano el que generara esta misma consecuencia no alcanzaría un nivel tan alto de repercusión como cuando una falla es producto de un sistema inteligente.

Los modelos causales precisamente buscan mejorar la forma en que un sistema toma decisiones incluyendo un elemento adicional al modelo probabilístico y consiste en realizar la inclusión de los datos ya que son importantes fuentes de información incluyendo precisamente este esquema de cómo diferentes observaciones y agentes externos afectan las probabilidades de ocurrencia de ciertos eventos permitiendo así anteponerse ante posibles y variados escenarios y cómo poder actuar frente a ellos. Actualmente se está prestando bastante atención a la inclusión de modelos causales en la implementación de sistemas inteligentes ya que permiten ir cerrando poco a poco la gran cantidad de brechas que aún se tienen en el proceso de la implementación para poder llegar al desarrollo de una verdadera inteligencia artificial.