# The Limitations of Opaque Learning Machines
Diana Laura Jiménez López

No es raro que en el día a día escuchemos los términos "Deep Learning", "Neural Networks" entre otros similares, y es que ha despertado una fascinación por este tipo de métodos para desarrollar Inteligencia Artifical, y no es casualidad, este tipo de métodos han obtenido excelentes resultados, sin embargo, el que un método, idea, herramienta, etc. funcione para algunos problemas no quiere decir que funcione para todos. Lo que ha estado sucediendo es algo parecido a la frase  "Cuándo la única herramienta que tienes es un martillo, todo problema empieza a parecerse a un clavo", aunque en este caso más bien seria "Cuándo la herramienta famosa es un martillo, quieres que todo sea un clavo" y es que no se puede negar que ultimamente todo tipo de problemas se buscan solucionar con Deep Learning, pero la realidad es que: 
1. No es lo único que hay 
2.  No es el método idóneo para todo tipo de problemas 

En el artículo "The limitations of Opaque Leaning Machines" se nos presenta el problema de no saber que esta sucediendo en realidad en un modelo del tipo de los mencionados y es que bien se sabe que son llamados "cajas negras", simplemente se tienen un montón de datos (y normalmante tienen que ser MUCHOS datos para que funcione bien) que se le alimentan a una red que ajusta misteriosos parámetros para arrojar una solución, cuando se trata por ejemplo, de desiciones, no sabemos porqué tomó esa desición, ni que camino siguió, lo que cuál representa un problema no solo para mejorar el modelo o justificar resultados, si no que presenta un problema para la solución de cierto tipo de problemas. 

Uno de los problemas que no se pueden resolver de forma óptima con redes neuronales son los problemas de tipo causal, no pueden atacar problemas "What if ...", y esto como se menciona en el artículo, hace que se pierda gran parte de lo que la Inteligencia Artificial busca, que  es tratar de que las máquinas realicen procesos que actualmente los humanos hacen mejor, ya que, ese tipo de razonamiento en fundamental para el ser humano, su existencia y desarrollo. 

A lo largo de la historia humana las preguntad de tipo "What if" son las que han ayudado al ser humano a entender el mundo y sus fenómenos, por ejemplo "¿Qué pasa si congelo este litro de agua?" o "¿Qué pasará si conecto este metal con este otro?" e incluso a entender un mundo hipotético, en el que no se hará ninguna prueba si no simplemente se razonará sobre una posibilidad, y desafortunadamente, este tipo de preguntas no pueden ser respondidas por los mismos modelos que responden ¿Esto es un perro o un gato? Ya que como se puede observar facilmente, son tipos de análisis completamente diferentes. 

Personalmente considero que las redes neuronales son geniales y definitivamente un "arma" muy fuerte para emplear en la solución de problemas de Inteligencia Artificial, sin embargo es un poco frustrante el que muchas peronas no puedan ver o pensar más allá de estas, si bien han obtenido resultados increibles, los costos en datos e infraestructura son altos, y se dejan de lado las soluciones creativas, todo problema se le quiere aventar a una red neuronal, e incluso si el problema se pudiera resolver bien con una red neuronal, ¿qué pasa si no se cuenta con datos suficientes?, ¿qué pasa si no se cuenta con la infraestructura adecuada? Hay que voltear a ver otras herramientas y siempre tener presente que los problemas de la Inteligencia Artifical son tan bastos y algunos tan complejos que quizá no estamos ni cerca de resolverlos, y eso no es negativo, hay todo un camino que recorrer.


## Referencias
- Pearl, Judea. “[The Limitations of Opaque Learning Machines](https://ftp.cs.ucla.edu/pub/stat_ser/r489.pdf).” _Possible Minds: Twenty-Five Ways of Looking at AI_, 2019, 13–19.
