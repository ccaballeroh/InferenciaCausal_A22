Centro de Investigación en Computación del IPN
José Alfredo Torres Gonzalez
B210618
23/02/2022

**Reporte sobre The Limitations of Opaque Learning Machines**

Leer The Limitation of Opaque Learning Machines me dejó reflexivo respecto al tema y la pregunta de si realmente seremos capaces, como especie humana, de desarrollar una inteligencia y conciencia artificial de nivel superior.

El reciente despegue de las redes neuronales profundas en diferentes campos de nuestro día a día, genera una sensación de estar ya muy cerca de tener sistemas de inteligencia artifical capaces de razonar e interactuar de forma similar a como lo haríamos nosotros, pero todo eso puede ser un simple espejismo, ya que aún no es claro cómo se sobrellevarán las barreras y limitantes que nos impone dicha tecnología. Primero que nada las redes neuronales son cajas negras que funcionan, sin saber realmente cómo; se trata de una interpolación de muchos datos con los que se modela una función matemática para poder entender fenómenos y extrapolar resultados, pero no queda del todo claro su proceso entre las variables de entrada y la respuesta de salida, lo que genera dudas sobre su verdadero potencial. 

La aplicación de estos modelos, nos ha llevado a progresar radicalmente en muchas áreas como la medicina, al obtener resultados mucho más precisos y confiables,  lo que nos lleva a creer que este es el camino a seguir sin importar su poca transaparencia en el proceso. Se le llega a comparar con el cerebro humano en el sentido de que funciona aunque no entendamos del todo sus procesos, pero de acuerdo con Judea Pearl, lo que nos hace especiales y diferentes de otros seres vivos es nuestra capacidad de representar nuestro entorno mentalente, para manipularlo y de esta forma llegar a nuevos escenarios. Lo cual es algo de lo que aún carecen los sistemas de aprendizaje máquina, no siendo capaces de generar respuestas a preguntas como "¿Qué pasará si hago esto?" o "¿Que pasaría si algo llegara a ser de x forma?". Para eso se necesita un entendimiento del entorno y su manipulación.

Jeff Dean en una conferencia de TED, reconoce las limitantes existentes con el aprendizaje máquina. Como por ejemplo, que de momento los sistemas de deep learning sólo son capaces de enfocarse en un problema y cada que reciben un estímulo nuevo necesitan olvidar todo lo que ya han aprendido y comenzar de nuevo; es como si cada vez que quisieramos aprender algo nuevo, tuvieramos que olvidar toda nuestra educación. Por eso la importancia de pensar fuera de la caja y reflexionar sobre la utilidad de estos modelos a largo plazo.

En la lectura Judea Pearl nos da a entender que no siempre lo más eficiente es el camino correcto y es importante tomar conciencia de las limitaciones básicas descubiertas en el campo de la inferencia casual, con la finalidad de realmente poder desarrollar sistemas de inteligencia artifical capaces de interactual con nosotros de una manera mucho más humana. Esta clase de modelo a ciegas en el aprendizaje máquina impone limitaciones cognitivas en las tareas que podría llegar a desempeñar un IA. Es peligroso querer progresar con algo que no se entiende, se debe observar un panorma mucho más grande y transparente para poder progresar organicamente. Opciones hay, la decisión es nuestra y los puntos de vista son vitales. Me inspira leer sobre personas que prefieren pensar por fuera de la caja como Judea Pearl.

Referencias:
*Jeff Dean: AI isn’t as smart as you think -- but it could be | TED.* (2022, January 12). [Video]. YouTube. https://www.youtube.com/watch?v=J-FzHIQ7SOs